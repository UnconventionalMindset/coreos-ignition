variant: fcos
version: 1.4.0
passwd:
  groups:
    - name: homeuser
      gid: 1000
  users:
    - name: core
      uid: 1000
      groups:
        - docker
        - homeuser
      password_hash: $y$j9T$OVO6S5zyKdrnoYOq99WD31$L/mPYI9vAHqTqRDyT6sVjiMVoov/9GVQoKuRoIEPvNA
      ssh_authorized_keys:
        - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCoPJQAHkfSRIfS05ptesdKwTX7ererHcTZ7pKWi7yUqOQv1e2xpfNBcfx/trwzITJe9N7bwp7t6gpPY2/yBr8F6TenigFWhDaF3Qi9kdSlv64eOsPv6iTg0URH7RE4RQwdArPuwAEBA79BOVoJ0qG/zgn0LOlqYGE/EameYxtgzDJNjXPWOi6OkPKhOEc00+wWGucsCw/8a6rzaMbQHn647yiS7XUJ9/QgMwZ5tqT+Fw/1dxzV4zrWK5MVEXlN5wRZEzukadPQJKyZhhhx3o7MqEVOsTHvyBln6NVJGFawQY7B+ffN/+9n6pEuskWCqngywqAvDXyRS7zD/Dxqv5pjzSQI2fkyuM21oRcKlSYx2AB4L46J6MRJ4ZLA5dhY0fwv868F5VFmJZ2AsDmaGFCqdXTMCv6VRnghJo75oybv+/eoV53NETrTeB4XsPOxSZOHmK93zJzGw2hT4X/ZTvyVbnCyU+Z4sg2iU8ZVE3pHJi8ZQ3hadW0N+CAAmVQ+zsE= nousername

storage:
  files:
    - path: /etc/NetworkManager/system-connections/wired.nmconnection
      mode: 0600
      contents:
        inline: |
          [connection]
          id=wired
          uuid=0391d81b-ad5d-3f48-a41b-f157cefe7cb1
          type=ethernet
          autoconnect-priority=-999
          interface-name=enp6s18
          
          [ethernet]
          
          [ipv4]
          address1=192.168.31.200/24,192.168.31.1
          dns=192.168.31.1;8.8.8.8;
          may-fail=false
          method=manual
          
          [ipv6]
          addr-gen-mode=stable-privacy
          method=auto
    - path: /etc/hostname
      mode: 0644
      contents:
        inline: |
          coreos
    - path: /etc/profile.d/systemd-pager.sh
      mode: 0644
      contents:
        inline: |
          # Tell systemd to not use a pager when printing information
          export SYSTEMD_PAGER=cat
    - path: /etc/sysctl.d/20-silence-audit.conf
      mode: 0644
      contents:
        inline: |
          # Raise console message logging level from DEBUG (7) to WARNING (4)
          # to hide audit messages from the interactive console
          kernel.printk=4
    # Set vim as default editor
    # We use `zz-` as prefix to make sure this is processed last in order to
    # override any previously set defaults.
    - path: /etc/profile.d/zz-default-editor.sh
      overwrite: true
      contents:
        inline: |
          export EDITOR=vim
    - path: /var/home/core/download-apps-docker-composes.sh
      overwrite: true
      contents:
        inline: |
          #!/usr/bin/bash
          git clone --filter=blob:none --branch dev --no-checkout --depth 1 --sparse https://github.com/UnconventionalMindset/coreos-setup.git /var/home/core/coreos-setup
          cd /var/home/core/coreos-setup
          git sparse-checkout set apps
          git checkout
          mkdir /etc/docker/compose/
          mv /var/home/core/coreos-setup/apps/* /etc/docker/compose/
          rm -rf /var/home/core/coreos-setup
    - path: /var/home/core/deploy-stack.sh
      overwrite: true
      contents:
        inline: |
          #!/usr/bin/bash
          composes=($(ls /etc/docker/compose/))
          for (( i = 0; i < ${#composes[@]} ; i++ )); do
            systemctl start docker-compose@${composes[$i]}
          done
          
systemd:
  units:
    - name: download-apps-docker-composes.service
      enabled: true
      contents: |
        [Unit]
        Description=Downloads apps docker composes
        Wants=network-online.target
        After=network-online.target
        ConditionPathExists=!/var/lib/%N.stamp

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/usr/bin/bash /var/home/core/download-apps-docker-composes.sh
        ExecStart=/bin/touch /var/lib/%N.stamp

        [Install]
        WantedBy=multi-user.target
    # Installing vim as a layered package with rpm-ostree
    - name: rpm-ostree-install-vim.service
      enabled: true
      contents: |
        [Unit]
        Description=Layer vim with rpm-ostree
        Wants=network-online.target
        After=network-online.target
        # We run before `zincati.service` to avoid conflicting rpm-ostree
        # transactions.
        Before=zincati.service rpm-ostree-install-docker-compose.service
        ConditionPathExists=!/var/lib/%N.stamp

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        # `--allow-inactive` ensures that rpm-ostree does not return an error
        # if the package is already installed. This is useful if the package is
        # added to the root image in a future Fedora CoreOS release as it will
        # prevent the service from failing.
        ExecStart=/usr/bin/rpm-ostree install --apply-live --allow-inactive vim
        ExecStart=/bin/touch /var/lib/%N.stamp

        [Install]
        WantedBy=multi-user.target
    # Installing docker-compose as a layered package with rpm-ostree
    - name: rpm-ostree-install-docker-compose.service
      enabled: true
      contents: |
        [Unit]
        Description=Layer docker-compose with rpm-ostree
        Wants=network-online.target
        After=network-online.target
        # We run before `zincati.service` to avoid conflicting rpm-ostree
        # transactions.
        Before=zincati.service
        ConditionPathExists=!/var/lib/%N.stamp

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        # `--allow-inactive` ensures that rpm-ostree does not return an error
        # if the package is already installed. This is useful if the package is
        # added to the root image in a future Fedora CoreOS release as it will
        # prevent the service from failing.
        ExecStart=/usr/bin/rpm-ostree install --apply-live --allow-inactive docker-compose
        ExecStart=/bin/touch /var/lib/%N.stamp

        [Install]
        WantedBy=multi-user.target
    - name: docker-compose@.service
      contents: |
        [Unit]
        Description=%i service with docker compose
        PartOf=docker.service
        Wants=network-online.target docker.service rpm-ostree-install-docker-compose.service
        After=network-online.target rpm-ostree-install-docker-compose.service
        
        [Service]
        Type=oneshot
        RemainAfterExit=true
        WorkingDirectory=/etc/docker/compose/%i
        ExecStart=/usr/bin/docker-compose up -d --remove-orphans
        ExecStop=/usr/bin/docker-compose down

        [Install]
        WantedBy=multi-user.target
    - name: deploy-stack.service
      enabled: true
      contents: |
        [Unit]
        Description=Deploy stack with docker compose
        Wants=network-online.target docker.service rpm-ostree-install-docker-compose.service download-apps-docker-composes.service
        After=network-online.target rpm-ostree-install-docker-compose.service download-apps-docker-composes.service
        
        [Service]
        Type=oneshot
        RemainAfterExit=true
        ExecStart=/usr/bin/bash /var/home/core/deploy-stack.sh

        [Install]
        WantedBy=multi-user.target
    - name: var-mnt-shared.mount
      enabled: true
      contents: |
        [Unit]
        # After specifies the execution order because Require does not wait for depndencies to finish execution before starting the current service.
        After=NetworkManager-wait-online.service
        # Depend and start another service.
        Wants=NetworkManager-wait-online.service
        [Mount]
        What=192.168.31.109:/mnt/hdd1tb/shared
        Where=/var/mnt/shared
        Type=nfs
        Options=_netdev,auto
        [Install]
        WantedBy=local-fs.target
    - name: docker.portainer.service
      enabled: true
      contents: |-
        [Unit]
        Description=Portainer Admin Container
        After=docker.service var-mnt-shared.mount
        Requires=docker.service network.target network-online.target

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        TimeoutStartSec=0
        ExecStartPre=-/usr/bin/docker stop %n
        ExecStartPre=-/usr/bin/docker rm %n
        ExecStartPre=/usr/bin/docker pull portainer/portainer-ce:latest
        ExecStart=-/usr/bin/mkdir -p /mnt/shared/apps/docker/portainer
        # Privileged mode is required for binding to local socket to work due to SELINUX (https://github.com/portainer/portainer/issues/849)
        ExecStart=/usr/bin/docker run \
          --privileged=true \
          -d \
          -p 9000:9000 \
          --name %n \
          --restart always \
          -v /var/run/docker.sock:/var/run/docker.sock \
          -v /mnt/shared/apps/docker/portainer:/data \
          portainer/portainer-ce:latest \
            --templates https://raw.githubusercontent.com/UnconventionalMindset/portainer/main/template.json \
            --admin-password-file /data/.secrets/portainer_pass
        ExecStop=/usr/bin/docker stop -t 15 %n

        [Install]
        WantedBy=multi-user.target
    - name: serial-getty@ttyS0.service
      dropins:
      - name: autologin-core.conf
        contents: |
          [Service]
          # Override Execstart in main unit
          ExecStart=
          # Add new Execstart with `-` prefix to ignore failure
          ExecStart=-/usr/sbin/agetty --autologin core --noclear %I $TERM
          TTYVTDisallocate=no
    - name: failure.service
      enabled: true
      contents: |
        [Service]
        Type=oneshot
        ExecStart=/usr/bin/false
        RemainAfterExit=yes

        [Install]
        WantedBy=multi-user.target
    - name: etcd-member.service
      enabled: true
      contents: |
        [Unit]
        Description=Run a single node etcd
        After=network-online.target
        Wants=network-online.target

        [Service]
        ExecStartPre=mkdir -p /var/lib/etcd
        ExecStartPre=-/bin/podman kill etcd
        ExecStartPre=-/bin/podman rm etcd
        ExecStartPre=-/bin/podman pull quay.io/coreos/etcd
        ExecStart=/bin/podman run --name etcd --net=host \
                    --volume /var/lib/etcd:/etcd-data:z  \
                    quay.io/coreos/etcd:latest /usr/local/bin/etcd              \
                            --data-dir /etcd-data --name node1                  \
                            --initial-advertise-peer-urls http://127.0.0.1:2380 \
                            --listen-peer-urls http://127.0.0.1:2380            \
                            --advertise-client-urls http://127.0.0.1:2379       \
                            --listen-client-urls http://127.0.0.1:2379          \
                            --initial-cluster node1=http://127.0.0.1:2380
        ExecStop=/bin/podman stop etcd

        [Install]
        WantedBy=multi-user.target
